#!/usr/bin/env python3
"""
ã€guohxã€‘åˆ†æPythonç‰ˆæœ¬çš„processedæ•°æ®æ–‡ä»¶å†…å®¹
"""

import pickle
import sys
import os
from pathlib import Path

# ã€guohxã€‘æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, 'src')

def analyze_python_data():
    """ã€guohxã€‘åˆ†æPythonç‰ˆæœ¬çš„processedæ•°æ®"""
    
    processed_dir = Path("datasets_root/perm2k/processed/C3ProblemGenerator(VERSION=3.1, analyzer=())/")
    
    print("=" * 80)
    print("ã€guohxã€‘Pythonç‰ˆæœ¬ PROCESSED æ•°æ®åˆ†æ")
    print("=" * 80)
    
    if not processed_dir.exists():
        print("âŒ ç›®å½•ä¸å­˜åœ¨")
        return
    
    # ã€guohxã€‘éå†æ‰€æœ‰æ–‡ä»¶
    for file_path in processed_dir.iterdir():
        if file_path.is_file():
            print(f"\nğŸ“ æ–‡ä»¶: {file_path.name}")
            print(f"ğŸ“Š å¤§å°: {file_path.stat().st_size:,} bytes")
            print("-" * 60)
            
            try:
                # ã€guohxã€‘è¯»å–pickleæ–‡ä»¶
                with open(file_path, 'rb') as f:
                    data = pickle.load(f)
                
                print(f"ğŸ“‹ æ•°æ®ç±»å‹: {type(data)}")
                
                if isinstance(data, dict):
                    print(f"ğŸ”‘ å­—å…¸é”®: {list(data.keys())}")
                    total_problems = 0
                    
                    for key, value in data.items():
                        print(f"\n  ğŸ“‚ åˆ†é›†: {key}")
                        print(f"    ğŸ“Š ç±»å‹: {type(value)}")
                        print(f"    ğŸ“ˆ é•¿åº¦: {len(value) if hasattr(value, '__len__') else 'N/A'}")
                        
                        if hasattr(value, '__len__') and len(value) > 0:
                            total_problems += len(value)
                            
                            # ã€guohxã€‘åˆ†æç¬¬ä¸€ä¸ªé—®é¢˜
                            first_problem = value[0]
                            print(f"    ğŸ” ç¬¬ä¸€ä¸ªé—®é¢˜ç±»å‹: {type(first_problem)}")
                            
                            # ã€guohxã€‘å¦‚æœæ˜¯C3Problemï¼Œæ˜¾ç¤ºå…¶å±æ€§
                            if hasattr(first_problem, '__dict__'):
                                print(f"    ğŸ“ å±æ€§: {list(first_problem.__dict__.keys())}")
                                
                                # ã€guohxã€‘æ˜¾ç¤ºä¸€äº›å…³é”®å±æ€§
                                for attr in ['repo_name', 'commit_hash', 'file_path', 'edit_type']:
                                    if hasattr(first_problem, attr):
                                        attr_value = getattr(first_problem, attr)
                                        print(f"      {attr}: {attr_value}")
                
                elif isinstance(data, list):
                    print(f"ğŸ“ˆ åˆ—è¡¨é•¿åº¦: {len(data)}")
                    if len(data) > 0:
                        first_item = data[0]
                        print(f"ğŸ” ç¬¬ä¸€ä¸ªå…ƒç´ ç±»å‹: {type(first_item)}")
                        if hasattr(first_item, '__dict__'):
                            print(f"ğŸ“ å±æ€§: {list(first_item.__dict__.keys())}")
                
                print(f"\nâœ… æ€»é—®é¢˜æ•°é‡: {total_problems if 'total_problems' in locals() else 'N/A'}")
                
            except Exception as e:
                print(f"âŒ è¯»å–é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
            
            print("=" * 80)

def analyze_single_problem():
    """ã€guohxã€‘è¯¦ç»†åˆ†æå•ä¸ªé—®é¢˜"""
    
    print("\n" + "=" * 80)
    print("ã€guohxã€‘è¯¦ç»†åˆ†æå•ä¸ªé—®é¢˜")
    print("=" * 80)
    
    # ã€guohxã€‘é€‰æ‹©ä¸€ä¸ªè¾ƒå°çš„æ–‡ä»¶è¿›è¡Œåˆ†æ
    file_path = Path("datasets_root/perm2k/processed/C3ProblemGenerator(VERSION=3.1, analyzer=())/deepseek-ai~DeepSeek-V3(1000, is_training=False)")
    
    if not file_path.exists():
        print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    try:
        with open(file_path, 'rb') as f:
            data = pickle.load(f)
        
        if isinstance(data, dict) and len(data) > 0:
            # ã€guohxã€‘è·å–ç¬¬ä¸€ä¸ªåˆ†é›†çš„ç¬¬ä¸€ä¸ªé—®é¢˜
            first_split = list(data.keys())[0]
            first_problem = data[first_split][0]
            
            print(f"ğŸ“‚ åˆ†é›†: {first_split}")
            print(f"ğŸ” é—®é¢˜ç±»å‹: {type(first_problem)}")
            print(f"ğŸ“ æ‰€æœ‰å±æ€§:")
            
            for attr_name, attr_value in first_problem.__dict__.items():
                print(f"  {attr_name}: {type(attr_value)} = {attr_value}")
                
    except Exception as e:
        print(f"âŒ åˆ†æé”™è¯¯: {e}")

if __name__ == "__main__":
    analyze_python_data()
    analyze_single_problem() 