#!/usr/bin/env python3
"""
ã€guohxã€‘ä¿®å¤ç‰ˆæœ¬çš„pkl_to_jsonè„šæœ¬ï¼Œé€‚é…ä½ çš„æ•°æ®ç»“æ„
"""

import sys
import pickle
import json
from dataclasses import is_dataclass, fields
from pathlib import Path

# ã€guohxã€‘æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, "/Users/feiyu/Desktop/code/NewCoEditor/src")

try:
    from coeditor.common import *
    from coeditor.dataset import *
    print("âœ… coeditoræ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ coeditoræ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("ğŸ”„ ç»§ç»­æ‰§è¡Œï¼Œä½†å¯èƒ½æ— æ³•å¤„ç†æŸäº›ç‰¹æ®Šç±»å‹")

def instance_to_json(obj: Any) -> Dict[str, Any]:
    """
    ã€guohxã€‘å°†dataclasså®ä¾‹æˆ–dictå®ä¾‹åºåˆ—åŒ–ä¸ºJSONå¯åºåˆ—åŒ–çš„å­—å…¸
    """
    if not is_dataclass(obj) and not isinstance(obj, dict):
        raise TypeError(f"Expected a dataclass instance, got {type(obj).__name__}")
    
    def _serialize(value: Any) -> Any:
        if is_dataclass(value):
            result = {"__class__": type(value).__name__}

            for field in fields(value):
                field_value = getattr(value, field.name)
                result[field.name] = _serialize(field_value)

            return result
        elif isinstance(value, dict):
            return {k: _serialize(v) for k, v in value.items()}
        elif isinstance(value, (list, tuple, set)):
            return [_serialize(item) for item in value]
        # ã€guohxã€‘å¤„ç†NumPyæ•°ç»„
        elif hasattr(value, 'tolist'):  # å…¼å®¹numpyæ•°ç»„
            return value.tolist()
        # ã€guohxã€‘å¤„ç†rangeå¯¹è±¡
        elif isinstance(value, range):
            return {
                "__type__": "range",
                "start": value.start,
                "stop": value.stop,
                "step": value.step
            }
        else:
            return value
    
    return _serialize(obj)

def serialize_to_json(obj: Any, fp: Optional[str | Path] = None, indent: int = 2) -> Optional[str]:
    """
    ã€guohxã€‘å°†å¯¹è±¡åºåˆ—åŒ–ä¸ºJSONå­—ç¬¦ä¸²æˆ–å†™å…¥æ–‡ä»¶
    """
    data = instance_to_json(obj)
    
    if fp is not None:
        with open(fp, 'w') as f:
            json.dump(data, f, indent=indent)
        return None
    
    return json.dumps(data, indent=indent)

def analyze_and_convert():
    """ã€guohxã€‘åˆ†æå¹¶è½¬æ¢ä½ çš„æ•°æ®æ–‡ä»¶"""
    
    # ã€guohxã€‘è®¾ç½®æ–‡ä»¶è·¯å¾„
    pickle_abs_path = Path("/Users/feiyu/Desktop/code/NewCoEditor/datasets_root/perm2k/processed/C3ProblemGenerator(VERSION=3.1, analyzer=())/deepseek-ai~DeepSeek-V3(1000, is_training=False)")
    json_abs_path = Path("/Users/feiyu/Desktop/code/NewCoEditor/datasets_root/perm2k/")
    
    print(f"ğŸ“ è¯»å–æ–‡ä»¶: {pickle_abs_path}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {json_abs_path}")
    
    if not pickle_abs_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {pickle_abs_path}")
        return
    
    try:
        # ã€guohxã€‘è¯»å–pickleæ–‡ä»¶
        with open(pickle_abs_path, "rb") as f:
            problems = pickle.load(f)
        
        print(f"ğŸ“‹ æ•°æ®ç±»å‹: {type(problems)}")
        
        if isinstance(problems, dict):
            print(f"ğŸ”‘ å­—å…¸é”®: {list(problems.keys())}")
            
            # ã€guohxã€‘éå†æ¯ä¸ªåˆ†é›†
            for split_name, split_data in problems.items():
                print(f"\nğŸ“‚ åˆ†é›†: {split_name}")
                print(f"ğŸ“Š ç±»å‹: {type(split_data)}")
                print(f"ğŸ“ˆ é•¿åº¦: {len(split_data) if hasattr(split_data, '__len__') else 'N/A'}")
                
                if hasattr(split_data, '__len__') and len(split_data) > 0:
                    # ã€guohxã€‘è½¬æ¢ç¬¬ä¸€ä¸ªé—®é¢˜ä¸ºJSON
                    first_problem = split_data[0]
                    print(f"ğŸ” ç¬¬ä¸€ä¸ªé—®é¢˜ç±»å‹: {type(first_problem)}")
                    print(f"ğŸ“ ç±»å: {first_problem.__class__.__name__}")
                    
                    # ã€guohxã€‘ä¿å­˜ç¬¬ä¸€ä¸ªé—®é¢˜
                    output_file = json_abs_path / f"sample_problem_{split_name}_0.json"
                    serialize_to_json(first_problem, output_file)
                    print(f"âœ… å·²ä¿å­˜åˆ°: {output_file}")
                    
                    # ã€guohxã€‘ä¿å­˜æ•´ä¸ªåˆ†é›†ï¼ˆå¯é€‰ï¼Œå¯èƒ½å¾ˆå¤§ï¼‰
                    if len(split_data) <= 10:  # åªä¿å­˜å°æ•°æ®é›†
                        output_file = json_abs_path / f"problems_{split_name}.json"
                        serialize_to_json(split_data, output_file)
                        print(f"âœ… å·²ä¿å­˜æ•´ä¸ªåˆ†é›†åˆ°: {output_file}")
                    else:
                        print(f"âš ï¸ åˆ†é›†å¤ªå¤§({len(split_data)}ä¸ªé—®é¢˜)ï¼Œè·³è¿‡ä¿å­˜æ•´ä¸ªåˆ†é›†")
        
        elif isinstance(problems, list):
            print(f"ğŸ“ˆ åˆ—è¡¨é•¿åº¦: {len(problems)}")
            if len(problems) > 0:
                first_problem = problems[0]
                print(f"ğŸ” ç¬¬ä¸€ä¸ªé—®é¢˜ç±»å‹: {type(first_problem)}")
                print(f"ğŸ“ ç±»å: {first_problem.__class__.__name__}")
                
                # ã€guohxã€‘ä¿å­˜ç¬¬ä¸€ä¸ªé—®é¢˜
                output_file = json_abs_path / "sample_problem_0.json"
                serialize_to_json(first_problem, output_file)
                print(f"âœ… å·²ä¿å­˜åˆ°: {output_file}")
        
        print("\nğŸ‰ åˆ†æå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ å¤„ç†é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    analyze_and_convert() 