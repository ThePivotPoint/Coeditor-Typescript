{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d371e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import json\n",
    "from dataclasses import is_dataclass, fields\n",
    "\n",
    "sys.path.insert(0,r\"/Users/feiyu/Desktop/code/NewCoEditor/src\")\n",
    "from coeditor.common import *\n",
    "from coeditor.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47e04659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_to_json(obj: Any) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Serialize a dataclass instance or dict instance to a JSON-serializable dictionary.\n",
    "    \n",
    "    Args:\n",
    "        obj: A dataclass instance to serialize\n",
    "        include_class_name: Whether to include the class name as a key in the output\n",
    "    \n",
    "    Returns:\n",
    "        A JSON-serializable dictionary representing the dataclass\n",
    "    \n",
    "    Example:\n",
    "        >>> @dataclass\n",
    "        >>> class B:\n",
    "        >>>     num: int\n",
    "        >>> @dataclass\n",
    "        >>> class A:\n",
    "        >>>     obj: B\n",
    "        >>> dataclass_to_json(A(obj=B(num=1)))\n",
    "        {'A': {'obj': {'B': {'num': 1}}}}\n",
    "    \"\"\"\n",
    "    if not is_dataclass(obj) and not isinstance(obj, dict):\n",
    "        raise TypeError(f\"Expected a dataclass instance, got {type(obj).__name__}\")\n",
    "    \n",
    "    def _serialize(value: Any) -> Any:\n",
    "        if is_dataclass(value):\n",
    "            result = {\"__class__\": type(value).__name__}\n",
    "\n",
    "            for field in fields(value):\n",
    "                field_value = getattr(value, field.name)\n",
    "                result[field.name] = _serialize(field_value)\n",
    "\n",
    "            return result\n",
    "        elif isinstance(value, dict):\n",
    "            return {k: _serialize(v) for k, v in value.items()}\n",
    "        elif isinstance(value, (list, tuple, set)):\n",
    "            return [_serialize(item) for item in value]\n",
    "        # Handle NumPy arrays\n",
    "        elif isinstance(value, np.ndarray):\n",
    "            return value.tolist()\n",
    "        # Handle range objects\n",
    "        elif isinstance(value, range):\n",
    "            return {\n",
    "                \"__type__\": \"range\",\n",
    "                \"start\": value.start,\n",
    "                \"stop\": value.stop,\n",
    "                \"step\": value.step\n",
    "            }\n",
    "        else:\n",
    "            return value\n",
    "    \n",
    "    return _serialize(obj)\n",
    "\n",
    "def serialize_to_json(obj: Any, fp: Optional[str | Path] = None, indent: int = 2) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Serialize a dataclass instance to a JSON string or file.\n",
    "    \n",
    "    Args:\n",
    "        obj: A dataclass instance to serialize\n",
    "        fp: Optional file path to write the JSON to\n",
    "        indent: Number of spaces for indentation in the JSON output\n",
    "    \n",
    "    Returns:\n",
    "        JSON string if fp is None, otherwise None (writes to file)\n",
    "    \"\"\"\n",
    "    data = instance_to_json(obj)\n",
    "    \n",
    "    if fp is not None:\n",
    "        with open(fp, 'w') as f:\n",
    "            json.dump(data, f, indent=indent)\n",
    "        return None\n",
    "    \n",
    "    return json.dumps(data, indent=indent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a8ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_abs_path = Path(\"/Users/feiyu/Desktop/code/NewCoEditor/datasets_root/perm2k/processed/C3ProblemGenerator(VERSION=3.1, analyzer=())/deepseek-ai~DeepSeek-V3(1000, is_training=False)\")\n",
    "json_abs_path = Path(WORK_DIR) / \"datasets_root\"\n",
    "\n",
    "split = (\"train\", \"test\", \"valid\")\n",
    "\n",
    "with open(pickle_abs_path, \"rb\") as f:\n",
    "    problems: C3ProblemDataset[C3Problem] = pickle.load(f)\n",
    "\n",
    "def serialize_dataset(split: Tuple[str, ...]) -> None:\n",
    "        filtered_problems = {s: problems[s] for s in split}\n",
    "        serialize_to_json(filtered_problems, json_abs_path / f\"problems_{'_'.join(split)}.json\")\n",
    "\n",
    "def serialize_single_instance(split: str, id: int) -> None:\n",
    "    with open(pickle_abs_path, \"rb\") as f:\n",
    "        problems: C3ProblemDataset[C3Problem] = pickle.load(f)\n",
    "        serialize_to_json(problems[split][id], json_abs_path / f\"problems_{split}_{id}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00e4afcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# serialize_dataset(split)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mserialize_single_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mserialize_single_instance\u001b[39m\u001b[34m(split, id)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pickle_abs_path, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     15\u001b[39m     problems: C3ProblemDataset[C3Problem] = pickle.load(f)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     serialize_to_json(\u001b[43mproblems\u001b[49m\u001b[43m[\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;28mid\u001b[39m], json_abs_path / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mproblems_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.json\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# serialize_dataset(split)\n",
    "serialize_single_instance(\"train\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5093233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coeditor_ts_0711",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
